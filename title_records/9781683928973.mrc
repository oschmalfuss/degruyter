03591nmm a2200649Ia 45000010014000000030009000140050017000230060019000400070015000590080041000740200018001150240031001330350021001640350022001850400033002070410008002400440012002480500025002600720023002850820015003081000081003232450096004042640062005002640011005623000031005733360026006043370026006303380036006563470024006924900029007165060104007455201159008495300026020085380049020345460016020835880112020996500048022116500029022596500032022886500052023206500026023726500034023986530144024327760024025767760025026008560042026258560049026678560080027169120022027969120014028189120015028329120023028479120016028709120016028869120015029029120024029179781683928973DE-B159720240326120151.0m|||||o||d||||||||cr || ||||||||240326t20232024xxu    fo  d z      eng d  a97816839289737 a10.1515/97816839289732doi  a(DE-B1597)658521  a(OCoLC)1425556353  aDE-B1597bengcDE-B1597erda0 aeng  axxucUS 4aQA76.9.N38bC36 2023 7aCOM0000002bisacsh04a007.132231 aCampesato, Oswald, eauthor.4aut4http://id.loc.gov/vocabulary/relators/aut10aTransformer, BERT, and GPT :bIncluding ChatGPT and Prompt Engineering /cOswald Campesato. 1aDulles, VA : bMercury Learning and Information, c[2023] 4cÂ©2024  a1 online resource (364 p.)  atextbtxt2rdacontent  acomputerbc2rdamedia  aonline resourcebcr2rdacarrier  atext filebPDF2rda0 aMLI Generative AI Series0 arestricted accessuhttp://purl.org/coar/access_right/c_16ecfonline access with authorization2star  aThis book provides a comprehensive group of topics covering the details of the Transformer architecture, BERT models, and the GPT series, including GPT-3 and GPT-4. Spanning across ten chapters, it begins with foundational concepts such as the attention mechanism, then tokenization techniques, explores the nuances of Transformer and BERT architectures, and culminates in advanced topics related to the latest in the GPT series, including ChatGPT. Key chapters provide insights into the evolution and significance of attention in deep learning, the intricacies of the Transformer architecture, a two-part exploration of the BERT family, and hands-on guidance on working with GPT-3. The concluding chapters present an overview of ChatGPT, GPT-4, and visualization using generative AI. In addition to the primary topics, the book also covers influential AI organizations such as DeepMind, OpenAI, Cohere, Hugging Face, and more. Readers will gain a comprehensive understanding of the current landscape of NLP models, their underlying architectures, and practical applications. Features companion files with numerous code samples and figures from the book.  aIssued also in print.  aMode of access: Internet via World Wide Web.  aIn English.0 aDescription based on online resource; title from PDF title page (publisher's Web site, viewed 26. Mrz 2024) 0aArtificial intelligencexComputer programs. 0aArtificial intelligence. 0aHuman-computer interaction. 0aNatural language processing (Computer science). 0aSoftware engineering. 7aCOMPUTERS / General.2bisacsh  anatural language processing, expert systems, visualization, AI, artificial intelligence, deep learning, machine learning, computer science.0 cEPUBz97816839289660 cprintz978168392898040uhttps://doi.org/10.1515/978168392897340uhttps://www.degruyter.com/isbn/9781683928973423Coveruhttps://www.degruyter.com/document/cover/isbn/9781683928973/original  aEBA_CL_CHCOMSGSEN  aEBA_DGALL  aEBA_EBKALL  aEBA_ECL_CHCOMSGSEN  aEBA_EEBKALL  aEBA_ESTMALL  aEBA_STMALL  aGBV-deGruyter-alles