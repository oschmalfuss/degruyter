03491nam a22005415i 45000010014000000030009000140050017000230060019000400070015000590080041000740200018001150240035001330350021001680350022001890400033002110410008002440440011002520720023002631000074002862450046003602640040004062640011004463000031004573360026004883370026005143380036005403470024005765050462006005060104010625201068011665380049022345460016022835880112022996500075024117730095024868560046025818560049026278560080026769120060027569120016028169120015028329120017028479120016028649120016028809120014028969120015029109120024029259782759831753DE-B159720240306014423.0m|||||o||d||||||||cr || ||||||||240306t20232023fr     fo  d z      eng d  a97827598317537 a10.1051/978-2-7598-3175-32doi  a(DE-B1597)677655  a(OCoLC)1409180232  aDE-B1597bengcDE-B1597erda0 aeng  afrcFR 7aMAT0290302bisacsh1 aLI, Qingna, eauthor.4aut4http://id.loc.gov/vocabulary/relators/aut10aModern Optimization Methods /cQingna LI. 1aLes Ulis : bEDP Sciences, c[2023] 4c©2023  a1 online resource (157 p.)  atextbtxt2rdacontent  acomputerbc2rdamedia  aonline resourcebcr2rdacarrier  atext filebPDF2rda00tFrontmatter -- tPreface -- tContents -- tChapter 1. Introduction -- tChapter 2. Fundamentals of Optimization -- tChapter 3. Line Search Methods -- tChapter 4. Trust Region Methods -- tChapter 5. Conjugate Gradient Methods -- tChapter 6. Semismooth Newton’s Method -- tChapter 7. Theory of Constrained Optimization -- tChapter 8. Penalty and Augmented Lagrangian Methods -- tChapter 9. Bilevel Optimization and Its Applications -- tBibliography0 arestricted accessuhttp://purl.org/coar/access_right/c_16ecfonline access with authorization2star  aWith the fast development of big data and artificial intelligence, a natural question is how do we analyze data more efficiently? One of the efficient ways is to use optimization. What is optimization? Optimization exists everywhere. People optimize. As long as you have choices, you do optimization. Optimization is the key of operations research. This book introduces the basic definitions and theory about numerical optimization, including optimality conditions for unconstrained and constrained optimization, as well as algorithms for unconstrained and constrained problems. Moreover, it also includes the nonsmooth Newton’s method, which plays an important role in large-scale numerical optimization. Finally, based on the author’s research experiences, several latest applications about optimization are introduced, including optimization algorithms for hypergraph matching, support vector machine and bilevel optimization approach for hyperparameter selection in machine learning. With these optimization tools, one can deal with data more efficiently.  aMode of access: Internet via World Wide Web.  aIn English.0 aDescription based on online resource; title from PDF title page (publisher's Web site, viewed 06. Mrz 2024) 7aMATHEMATICS / Probability & Statistics / Regression Analysis.2bisacsh08iTitle is part of eBook package:dDe GruytertDG Plus PP Package 2023 Part 2z978311117804240uhttps://doi.org/10.1051/978-2-7598-3175-340uhttps://www.degruyter.com/isbn/9782759831753423Coveruhttps://www.degruyter.com/document/cover/isbn/9782759831753/original  a978-3-11-117804-2  DG Plus PP Package 2023 Part 2b2023  aEBA_CL_MTPY  aEBA_EBKALL  aEBA_ECL_MTPY  aEBA_EEBKALL  aEBA_ESTMALL  aEBA_PPALL  aEBA_STMALL  aGBV-deGruyter-alles